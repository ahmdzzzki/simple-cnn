{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kode ini adalah implementasi CNN sederhana untuk klasifikasi gambar menggunakan dataset MNIST.\n",
    "Model ini akan melakukan training, testing, serta evaluasi dengan confusion matrix dan classification report.\n",
    "\n",
    "# Bagian 1: Persiapan Dataset MNIST\n",
    "Dataset MNIST adalah dataset gambar hitam-putih dari digit angka 0-9 dengan ukuran 28x28 piksel. Pada bagian ini, dataset MNIST akan di-download dan di-load ke dalam DataLoader PyTorch.\n",
    "\n",
    "Definisikan transformasi dataset (konversi gambar ke tensor dan normalisasi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),    # Ubah gambar menjadi tensor\n",
    "    transforms.Normalize((0.1307,), (0.3081,))  # Normalisasi untuk dataset MNIST\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [02:14<00:00, 73704.73it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 94097.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [01:14<00:00, 22014.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<00:00, 14936.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load dataset MNIST dari torchvision\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Membuat DataLoader untuk training dan testing\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=1000, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagian 2: Definisi Arsitektur CNN\n",
    "Model CNN ini terdiri dari dua lapisan convolutional dan dua lapisan fully connected. CNN digunakan untuk mendeteksi fitur dari gambar secara hierarkis, dan lapisan fully connected digunakan untuk klasifikasi akhir.\n",
    "\n",
    "Model CNN sederhana dengan dua lapisan convolutional dan dua fully connected layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        # Layer convolution pertama: input 1 channel (grayscale), output 32 filter\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        # Layer convolution kedua: input 32 channel, output 64 filter\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        # Fully connected layer pertama\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
    "        # Fully connected layer kedua (output 10 kelas)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Operasi forward pass untuk model\n",
    "        x = F.relu(self.conv1(x))        # Convolution pertama + ReLU\n",
    "        x = F.max_pool2d(x, 2)           # Pooling pertama (downsample)\n",
    "        x = F.relu(self.conv2(x))        # Convolution kedua + ReLU\n",
    "        x = F.max_pool2d(x, 2)           # Pooling kedua (downsample)\n",
    "        x = x.view(-1, 64 * 7 * 7)       # Flatten untuk input ke fully connected layer\n",
    "        x = F.relu(self.fc1(x))          # Fully connected layer pertama + ReLU\n",
    "        x = self.fc2(x)                  # Fully connected layer kedua (output)\n",
    "        return F.log_softmax(x, dim=1)   # Softmax untuk klasifikasi (logaritmik)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagian 3: Definisi Loss Function dan Optimizer\n",
    "Gunakan CrossEntropyLoss dan optimizer Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model, loss function, and optimizer\n",
    "model = SimpleCNN()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagian 4: Training Model\n",
    "Fungsi `train` digunakan untuk melatih model, sementara `test` digunakan untuk menguji performa model pada dataset uji. Pada setiap epoch, loss dan akurasi akan dihitung.\n",
    "\n",
    "Fungsi untuk melatih model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()  # Mode training\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()           # Set gradient ke 0\n",
    "        output = model(data)            # Forward pass\n",
    "        loss = criterion(output, target)  # Hitung loss\n",
    "        loss.backward()                 # Backpropagation\n",
    "        optimizer.step()                # Update bobot model\n",
    "\n",
    "        if batch_idx % 100 == 0:  # Setiap 100 batch, cetak status\n",
    "            print(f'Train Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)}]  Loss: {loss.item():.6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagian 5: Testing Model\n",
    "Fungsi untuk menguji model pada dataset uji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, test_loader):\n",
    "    model.eval()  # Mode evaluasi\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():  # Tidak perlu menghitung gradient\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += criterion(output, target).item()  # Hitung total loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)      # Prediksi kelas\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()  # Hitung jumlah prediksi benar\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)  # Hitung rata-rata loss\n",
    "\n",
    "    print(f'\\nTest set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(test_loader.dataset)}'\n",
    "          f' ({100. * correct / len(test_loader.dataset):.0f}%)\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagian 6: Konfigurasi Device\n",
    "Tentukan apakah menggunakan GPU atau CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleCNN(\n",
       "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (fc1): Linear(in_features=3136, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagian 7: Training dan Testing Loop\n",
    "Training dan testing selama 100 epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000]  Loss: 2.329236\n",
      "Train Epoch: 1 [6400/60000]  Loss: 0.246296\n",
      "Train Epoch: 1 [12800/60000]  Loss: 0.111787\n",
      "Train Epoch: 1 [19200/60000]  Loss: 0.185511\n",
      "Train Epoch: 1 [25600/60000]  Loss: 0.066838\n",
      "Train Epoch: 1 [32000/60000]  Loss: 0.040984\n",
      "Train Epoch: 1 [38400/60000]  Loss: 0.016773\n",
      "Train Epoch: 1 [44800/60000]  Loss: 0.072438\n",
      "Train Epoch: 1 [51200/60000]  Loss: 0.131698\n",
      "Train Epoch: 1 [57600/60000]  Loss: 0.012145\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 9849/10000 (98%)\n",
      "\n",
      "Train Epoch: 2 [0/60000]  Loss: 0.035300\n",
      "Train Epoch: 2 [6400/60000]  Loss: 0.042402\n",
      "Train Epoch: 2 [12800/60000]  Loss: 0.109446\n",
      "Train Epoch: 2 [19200/60000]  Loss: 0.050377\n",
      "Train Epoch: 2 [25600/60000]  Loss: 0.027939\n",
      "Train Epoch: 2 [32000/60000]  Loss: 0.130934\n",
      "Train Epoch: 2 [38400/60000]  Loss: 0.002464\n",
      "Train Epoch: 2 [44800/60000]  Loss: 0.001041\n",
      "Train Epoch: 2 [51200/60000]  Loss: 0.043945\n",
      "Train Epoch: 2 [57600/60000]  Loss: 0.028017\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 9856/10000 (99%)\n",
      "\n",
      "Train Epoch: 3 [0/60000]  Loss: 0.025519\n",
      "Train Epoch: 3 [6400/60000]  Loss: 0.001157\n",
      "Train Epoch: 3 [12800/60000]  Loss: 0.041294\n",
      "Train Epoch: 3 [19200/60000]  Loss: 0.009571\n",
      "Train Epoch: 3 [25600/60000]  Loss: 0.029483\n",
      "Train Epoch: 3 [32000/60000]  Loss: 0.055637\n",
      "Train Epoch: 3 [38400/60000]  Loss: 0.056007\n",
      "Train Epoch: 3 [44800/60000]  Loss: 0.031143\n",
      "Train Epoch: 3 [51200/60000]  Loss: 0.001575\n",
      "Train Epoch: 3 [57600/60000]  Loss: 0.016500\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 9897/10000 (99%)\n",
      "\n",
      "Train Epoch: 4 [0/60000]  Loss: 0.010568\n",
      "Train Epoch: 4 [6400/60000]  Loss: 0.023467\n",
      "Train Epoch: 4 [12800/60000]  Loss: 0.012296\n",
      "Train Epoch: 4 [19200/60000]  Loss: 0.054054\n",
      "Train Epoch: 4 [25600/60000]  Loss: 0.003710\n",
      "Train Epoch: 4 [32000/60000]  Loss: 0.006653\n",
      "Train Epoch: 4 [38400/60000]  Loss: 0.000448\n",
      "Train Epoch: 4 [44800/60000]  Loss: 0.059124\n",
      "Train Epoch: 4 [51200/60000]  Loss: 0.008067\n",
      "Train Epoch: 4 [57600/60000]  Loss: 0.080507\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 9880/10000 (99%)\n",
      "\n",
      "Train Epoch: 5 [0/60000]  Loss: 0.001933\n",
      "Train Epoch: 5 [6400/60000]  Loss: 0.073830\n",
      "Train Epoch: 5 [12800/60000]  Loss: 0.001044\n",
      "Train Epoch: 5 [19200/60000]  Loss: 0.000831\n",
      "Train Epoch: 5 [25600/60000]  Loss: 0.058207\n",
      "Train Epoch: 5 [32000/60000]  Loss: 0.000662\n",
      "Train Epoch: 5 [38400/60000]  Loss: 0.064144\n",
      "Train Epoch: 5 [44800/60000]  Loss: 0.012466\n",
      "Train Epoch: 5 [51200/60000]  Loss: 0.001322\n",
      "Train Epoch: 5 [57600/60000]  Loss: 0.016187\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 9894/10000 (99%)\n",
      "\n",
      "Train Epoch: 6 [0/60000]  Loss: 0.028703\n",
      "Train Epoch: 6 [6400/60000]  Loss: 0.013934\n",
      "Train Epoch: 6 [12800/60000]  Loss: 0.000236\n",
      "Train Epoch: 6 [19200/60000]  Loss: 0.002450\n",
      "Train Epoch: 6 [25600/60000]  Loss: 0.006615\n",
      "Train Epoch: 6 [32000/60000]  Loss: 0.001142\n",
      "Train Epoch: 6 [38400/60000]  Loss: 0.009364\n",
      "Train Epoch: 6 [44800/60000]  Loss: 0.001387\n",
      "Train Epoch: 6 [51200/60000]  Loss: 0.072029\n",
      "Train Epoch: 6 [57600/60000]  Loss: 0.013737\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 9893/10000 (99%)\n",
      "\n",
      "Train Epoch: 7 [0/60000]  Loss: 0.002945\n",
      "Train Epoch: 7 [6400/60000]  Loss: 0.005425\n",
      "Train Epoch: 7 [12800/60000]  Loss: 0.000159\n",
      "Train Epoch: 7 [19200/60000]  Loss: 0.001994\n",
      "Train Epoch: 7 [25600/60000]  Loss: 0.011123\n",
      "Train Epoch: 7 [32000/60000]  Loss: 0.001021\n",
      "Train Epoch: 7 [38400/60000]  Loss: 0.006264\n",
      "Train Epoch: 7 [44800/60000]  Loss: 0.009875\n",
      "Train Epoch: 7 [51200/60000]  Loss: 0.000213\n",
      "Train Epoch: 7 [57600/60000]  Loss: 0.000772\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 9886/10000 (99%)\n",
      "\n",
      "Train Epoch: 8 [0/60000]  Loss: 0.014273\n",
      "Train Epoch: 8 [6400/60000]  Loss: 0.000125\n",
      "Train Epoch: 8 [12800/60000]  Loss: 0.000269\n",
      "Train Epoch: 8 [19200/60000]  Loss: 0.000798\n",
      "Train Epoch: 8 [25600/60000]  Loss: 0.000093\n",
      "Train Epoch: 8 [32000/60000]  Loss: 0.000052\n",
      "Train Epoch: 8 [38400/60000]  Loss: 0.000122\n",
      "Train Epoch: 8 [44800/60000]  Loss: 0.000213\n",
      "Train Epoch: 8 [51200/60000]  Loss: 0.004480\n",
      "Train Epoch: 8 [57600/60000]  Loss: 0.003393\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 9877/10000 (99%)\n",
      "\n",
      "Train Epoch: 9 [0/60000]  Loss: 0.004227\n",
      "Train Epoch: 9 [6400/60000]  Loss: 0.021931\n",
      "Train Epoch: 9 [12800/60000]  Loss: 0.000421\n",
      "Train Epoch: 9 [19200/60000]  Loss: 0.000106\n",
      "Train Epoch: 9 [25600/60000]  Loss: 0.000296\n",
      "Train Epoch: 9 [32000/60000]  Loss: 0.000058\n",
      "Train Epoch: 9 [38400/60000]  Loss: 0.001780\n",
      "Train Epoch: 9 [44800/60000]  Loss: 0.000086\n",
      "Train Epoch: 9 [51200/60000]  Loss: 0.132969\n",
      "Train Epoch: 9 [57600/60000]  Loss: 0.046513\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 9910/10000 (99%)\n",
      "\n",
      "Train Epoch: 10 [0/60000]  Loss: 0.004860\n",
      "Train Epoch: 10 [6400/60000]  Loss: 0.016658\n",
      "Train Epoch: 10 [12800/60000]  Loss: 0.000197\n",
      "Train Epoch: 10 [19200/60000]  Loss: 0.000891\n",
      "Train Epoch: 10 [25600/60000]  Loss: 0.000019\n",
      "Train Epoch: 10 [32000/60000]  Loss: 0.000012\n",
      "Train Epoch: 10 [38400/60000]  Loss: 0.000747\n",
      "Train Epoch: 10 [44800/60000]  Loss: 0.028720\n",
      "Train Epoch: 10 [51200/60000]  Loss: 0.003120\n",
      "Train Epoch: 10 [57600/60000]  Loss: 0.000010\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 9898/10000 (99%)\n",
      "\n",
      "Train Epoch: 11 [0/60000]  Loss: 0.000168\n",
      "Train Epoch: 11 [6400/60000]  Loss: 0.012762\n",
      "Train Epoch: 11 [12800/60000]  Loss: 0.000021\n",
      "Train Epoch: 11 [19200/60000]  Loss: 0.000096\n",
      "Train Epoch: 11 [25600/60000]  Loss: 0.000398\n",
      "Train Epoch: 11 [32000/60000]  Loss: 0.057481\n",
      "Train Epoch: 11 [38400/60000]  Loss: 0.000055\n",
      "Train Epoch: 11 [44800/60000]  Loss: 0.000219\n",
      "Train Epoch: 11 [51200/60000]  Loss: 0.002562\n",
      "Train Epoch: 11 [57600/60000]  Loss: 0.018727\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 9919/10000 (99%)\n",
      "\n",
      "Train Epoch: 12 [0/60000]  Loss: 0.000816\n",
      "Train Epoch: 12 [6400/60000]  Loss: 0.000004\n",
      "Train Epoch: 12 [12800/60000]  Loss: 0.000336\n",
      "Train Epoch: 12 [19200/60000]  Loss: 0.001561\n",
      "Train Epoch: 12 [25600/60000]  Loss: 0.001884\n",
      "Train Epoch: 12 [32000/60000]  Loss: 0.000002\n",
      "Train Epoch: 12 [38400/60000]  Loss: 0.003349\n",
      "Train Epoch: 12 [44800/60000]  Loss: 0.003842\n",
      "Train Epoch: 12 [51200/60000]  Loss: 0.016834\n",
      "Train Epoch: 12 [57600/60000]  Loss: 0.000257\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 9922/10000 (99%)\n",
      "\n",
      "Train Epoch: 13 [0/60000]  Loss: 0.002108\n",
      "Train Epoch: 13 [6400/60000]  Loss: 0.000402\n",
      "Train Epoch: 13 [12800/60000]  Loss: 0.000489\n",
      "Train Epoch: 13 [19200/60000]  Loss: 0.000009\n",
      "Train Epoch: 13 [25600/60000]  Loss: 0.001586\n",
      "Train Epoch: 13 [32000/60000]  Loss: 0.000806\n",
      "Train Epoch: 13 [38400/60000]  Loss: 0.022178\n",
      "Train Epoch: 13 [44800/60000]  Loss: 0.009638\n",
      "Train Epoch: 13 [51200/60000]  Loss: 0.000222\n",
      "Train Epoch: 13 [57600/60000]  Loss: 0.000001\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 9865/10000 (99%)\n",
      "\n",
      "Train Epoch: 14 [0/60000]  Loss: 0.082497\n",
      "Train Epoch: 14 [6400/60000]  Loss: 0.015577\n",
      "Train Epoch: 14 [12800/60000]  Loss: 0.026788\n",
      "Train Epoch: 14 [19200/60000]  Loss: 0.000002\n",
      "Train Epoch: 14 [25600/60000]  Loss: 0.001108\n",
      "Train Epoch: 14 [32000/60000]  Loss: 0.004828\n",
      "Train Epoch: 14 [38400/60000]  Loss: 0.000041\n",
      "Train Epoch: 14 [44800/60000]  Loss: 0.000807\n",
      "Train Epoch: 14 [51200/60000]  Loss: 0.008853\n",
      "Train Epoch: 14 [57600/60000]  Loss: 0.005164\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 9906/10000 (99%)\n",
      "\n",
      "Train Epoch: 15 [0/60000]  Loss: 0.017475\n",
      "Train Epoch: 15 [6400/60000]  Loss: 0.000007\n",
      "Train Epoch: 15 [12800/60000]  Loss: 0.028273\n",
      "Train Epoch: 15 [19200/60000]  Loss: 0.001054\n",
      "Train Epoch: 15 [25600/60000]  Loss: 0.013824\n",
      "Train Epoch: 15 [32000/60000]  Loss: 0.000053\n",
      "Train Epoch: 15 [38400/60000]  Loss: 0.000125\n",
      "Train Epoch: 15 [44800/60000]  Loss: 0.000063\n",
      "Train Epoch: 15 [51200/60000]  Loss: 0.000309\n",
      "Train Epoch: 15 [57600/60000]  Loss: 0.039525\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 9908/10000 (99%)\n",
      "\n",
      "Train Epoch: 16 [0/60000]  Loss: 0.000057\n",
      "Train Epoch: 16 [6400/60000]  Loss: 0.000113\n",
      "Train Epoch: 16 [12800/60000]  Loss: 0.000015\n",
      "Train Epoch: 16 [19200/60000]  Loss: 0.000024\n",
      "Train Epoch: 16 [25600/60000]  Loss: 0.004994\n",
      "Train Epoch: 16 [32000/60000]  Loss: 0.000112\n",
      "Train Epoch: 16 [38400/60000]  Loss: 0.000078\n",
      "Train Epoch: 16 [44800/60000]  Loss: 0.000016\n",
      "Train Epoch: 16 [51200/60000]  Loss: 0.006317\n",
      "Train Epoch: 16 [57600/60000]  Loss: 0.000429\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 9893/10000 (99%)\n",
      "\n",
      "Train Epoch: 17 [0/60000]  Loss: 0.000041\n",
      "Train Epoch: 17 [6400/60000]  Loss: 0.000491\n",
      "Train Epoch: 17 [12800/60000]  Loss: 0.000004\n",
      "Train Epoch: 17 [19200/60000]  Loss: 0.000001\n",
      "Train Epoch: 17 [25600/60000]  Loss: 0.000018\n",
      "Train Epoch: 17 [32000/60000]  Loss: 0.000017\n",
      "Train Epoch: 17 [38400/60000]  Loss: 0.000108\n",
      "Train Epoch: 17 [44800/60000]  Loss: 0.000006\n",
      "Train Epoch: 17 [51200/60000]  Loss: 0.013638\n",
      "Train Epoch: 17 [57600/60000]  Loss: 0.000006\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 9919/10000 (99%)\n",
      "\n",
      "Train Epoch: 18 [0/60000]  Loss: 0.000050\n",
      "Train Epoch: 18 [6400/60000]  Loss: 0.000223\n",
      "Train Epoch: 18 [12800/60000]  Loss: 0.001772\n",
      "Train Epoch: 18 [19200/60000]  Loss: 0.000052\n",
      "Train Epoch: 18 [25600/60000]  Loss: 0.000012\n",
      "Train Epoch: 18 [32000/60000]  Loss: 0.003043\n",
      "Train Epoch: 18 [38400/60000]  Loss: 0.012786\n",
      "Train Epoch: 18 [44800/60000]  Loss: 0.000020\n",
      "Train Epoch: 18 [51200/60000]  Loss: 0.000011\n",
      "Train Epoch: 18 [57600/60000]  Loss: 0.001559\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 9913/10000 (99%)\n",
      "\n",
      "Train Epoch: 19 [0/60000]  Loss: 0.000048\n",
      "Train Epoch: 19 [6400/60000]  Loss: 0.000000\n",
      "Train Epoch: 19 [12800/60000]  Loss: 0.003646\n",
      "Train Epoch: 19 [19200/60000]  Loss: 0.000020\n",
      "Train Epoch: 19 [25600/60000]  Loss: 0.000005\n",
      "Train Epoch: 19 [32000/60000]  Loss: 0.000007\n",
      "Train Epoch: 19 [38400/60000]  Loss: 0.000000\n",
      "Train Epoch: 19 [44800/60000]  Loss: 0.000002\n",
      "Train Epoch: 19 [51200/60000]  Loss: 0.011343\n",
      "Train Epoch: 19 [57600/60000]  Loss: 0.000003\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 9883/10000 (99%)\n",
      "\n",
      "Train Epoch: 20 [0/60000]  Loss: 0.000009\n",
      "Train Epoch: 20 [6400/60000]  Loss: 0.002575\n",
      "Train Epoch: 20 [12800/60000]  Loss: 0.000062\n",
      "Train Epoch: 20 [19200/60000]  Loss: 0.010829\n",
      "Train Epoch: 20 [25600/60000]  Loss: 0.012211\n",
      "Train Epoch: 20 [32000/60000]  Loss: 0.000003\n",
      "Train Epoch: 20 [38400/60000]  Loss: 0.000854\n",
      "Train Epoch: 20 [44800/60000]  Loss: 0.002432\n",
      "Train Epoch: 20 [51200/60000]  Loss: 0.000043\n",
      "Train Epoch: 20 [57600/60000]  Loss: 0.000002\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 9920/10000 (99%)\n",
      "\n",
      "Train Epoch: 21 [0/60000]  Loss: 0.000143\n",
      "Train Epoch: 21 [6400/60000]  Loss: 0.000003\n",
      "Train Epoch: 21 [12800/60000]  Loss: 0.029031\n",
      "Train Epoch: 21 [19200/60000]  Loss: 0.000041\n",
      "Train Epoch: 21 [25600/60000]  Loss: 0.000005\n",
      "Train Epoch: 21 [32000/60000]  Loss: 0.000010\n",
      "Train Epoch: 21 [38400/60000]  Loss: 0.000011\n",
      "Train Epoch: 21 [44800/60000]  Loss: 0.000498\n",
      "Train Epoch: 21 [51200/60000]  Loss: 0.000143\n",
      "Train Epoch: 21 [57600/60000]  Loss: 0.047779\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 9911/10000 (99%)\n",
      "\n",
      "Train Epoch: 22 [0/60000]  Loss: 0.000003\n",
      "Train Epoch: 22 [6400/60000]  Loss: 0.004895\n",
      "Train Epoch: 22 [12800/60000]  Loss: 0.000739\n",
      "Train Epoch: 22 [19200/60000]  Loss: 0.000003\n",
      "Train Epoch: 22 [25600/60000]  Loss: 0.000350\n",
      "Train Epoch: 22 [32000/60000]  Loss: 0.000000\n",
      "Train Epoch: 22 [38400/60000]  Loss: 0.000010\n",
      "Train Epoch: 22 [44800/60000]  Loss: 0.000002\n",
      "Train Epoch: 22 [51200/60000]  Loss: 0.001358\n",
      "Train Epoch: 22 [57600/60000]  Loss: 0.000002\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 9907/10000 (99%)\n",
      "\n",
      "Train Epoch: 23 [0/60000]  Loss: 0.000017\n",
      "Train Epoch: 23 [6400/60000]  Loss: 0.000008\n",
      "Train Epoch: 23 [12800/60000]  Loss: 0.000017\n",
      "Train Epoch: 23 [19200/60000]  Loss: 0.098239\n",
      "Train Epoch: 23 [25600/60000]  Loss: 0.000063\n",
      "Train Epoch: 23 [32000/60000]  Loss: 0.000323\n",
      "Train Epoch: 23 [38400/60000]  Loss: 0.000128\n",
      "Train Epoch: 23 [44800/60000]  Loss: 0.000465\n",
      "Train Epoch: 23 [51200/60000]  Loss: 0.000017\n",
      "Train Epoch: 23 [57600/60000]  Loss: 0.051180\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 9892/10000 (99%)\n",
      "\n",
      "Train Epoch: 24 [0/60000]  Loss: 0.000009\n",
      "Train Epoch: 24 [6400/60000]  Loss: 0.000004\n",
      "Train Epoch: 24 [12800/60000]  Loss: 0.000002\n",
      "Train Epoch: 24 [19200/60000]  Loss: 0.000000\n",
      "Train Epoch: 24 [25600/60000]  Loss: 0.000000\n",
      "Train Epoch: 24 [32000/60000]  Loss: 0.000000\n",
      "Train Epoch: 24 [38400/60000]  Loss: 0.003317\n",
      "Train Epoch: 24 [44800/60000]  Loss: 0.000000\n",
      "Train Epoch: 24 [51200/60000]  Loss: 0.000079\n",
      "Train Epoch: 24 [57600/60000]  Loss: 0.000135\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 9896/10000 (99%)\n",
      "\n",
      "Train Epoch: 25 [0/60000]  Loss: 0.012229\n",
      "Train Epoch: 25 [6400/60000]  Loss: 0.000000\n",
      "Train Epoch: 25 [12800/60000]  Loss: 0.000002\n",
      "Train Epoch: 25 [19200/60000]  Loss: 0.000047\n",
      "Train Epoch: 25 [25600/60000]  Loss: 0.000013\n",
      "Train Epoch: 25 [32000/60000]  Loss: 0.015300\n",
      "Train Epoch: 25 [38400/60000]  Loss: 0.000000\n",
      "Train Epoch: 25 [44800/60000]  Loss: 0.000000\n",
      "Train Epoch: 25 [51200/60000]  Loss: 0.000014\n",
      "Train Epoch: 25 [57600/60000]  Loss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 9919/10000 (99%)\n",
      "\n",
      "Train Epoch: 26 [0/60000]  Loss: 0.000002\n",
      "Train Epoch: 26 [6400/60000]  Loss: 0.000009\n",
      "Train Epoch: 26 [12800/60000]  Loss: 0.038373\n",
      "Train Epoch: 26 [19200/60000]  Loss: 0.000004\n",
      "Train Epoch: 26 [25600/60000]  Loss: 0.000002\n",
      "Train Epoch: 26 [32000/60000]  Loss: 0.000000\n",
      "Train Epoch: 26 [38400/60000]  Loss: 0.000004\n",
      "Train Epoch: 26 [44800/60000]  Loss: 0.000001\n",
      "Train Epoch: 26 [51200/60000]  Loss: 0.000001\n",
      "Train Epoch: 26 [57600/60000]  Loss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 9915/10000 (99%)\n",
      "\n",
      "Train Epoch: 27 [0/60000]  Loss: 0.000001\n",
      "Train Epoch: 27 [6400/60000]  Loss: 0.000006\n",
      "Train Epoch: 27 [12800/60000]  Loss: 0.000001\n",
      "Train Epoch: 27 [19200/60000]  Loss: 0.142727\n",
      "Train Epoch: 27 [25600/60000]  Loss: 0.000003\n",
      "Train Epoch: 27 [32000/60000]  Loss: 0.000000\n",
      "Train Epoch: 27 [38400/60000]  Loss: 0.000000\n",
      "Train Epoch: 27 [44800/60000]  Loss: 0.000000\n",
      "Train Epoch: 27 [51200/60000]  Loss: 0.000001\n",
      "Train Epoch: 27 [57600/60000]  Loss: 0.000015\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 9894/10000 (99%)\n",
      "\n",
      "Train Epoch: 28 [0/60000]  Loss: 0.000000\n",
      "Train Epoch: 28 [6400/60000]  Loss: 0.000048\n",
      "Train Epoch: 28 [12800/60000]  Loss: 0.000339\n",
      "Train Epoch: 28 [19200/60000]  Loss: 0.000033\n",
      "Train Epoch: 28 [25600/60000]  Loss: 0.000001\n",
      "Train Epoch: 28 [32000/60000]  Loss: 0.000007\n",
      "Train Epoch: 28 [38400/60000]  Loss: 0.000001\n",
      "Train Epoch: 28 [44800/60000]  Loss: 0.000101\n",
      "Train Epoch: 28 [51200/60000]  Loss: 0.000002\n",
      "Train Epoch: 28 [57600/60000]  Loss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 9911/10000 (99%)\n",
      "\n",
      "Train Epoch: 29 [0/60000]  Loss: 0.000000\n",
      "Train Epoch: 29 [6400/60000]  Loss: 0.000001\n",
      "Train Epoch: 29 [12800/60000]  Loss: 0.000007\n",
      "Train Epoch: 29 [19200/60000]  Loss: 0.000000\n",
      "Train Epoch: 29 [25600/60000]  Loss: 0.000000\n",
      "Train Epoch: 29 [32000/60000]  Loss: 0.000000\n",
      "Train Epoch: 29 [38400/60000]  Loss: 0.000001\n",
      "Train Epoch: 29 [44800/60000]  Loss: 0.000128\n",
      "Train Epoch: 29 [51200/60000]  Loss: 0.005363\n",
      "Train Epoch: 29 [57600/60000]  Loss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 9910/10000 (99%)\n",
      "\n",
      "Train Epoch: 30 [0/60000]  Loss: 0.000026\n",
      "Train Epoch: 30 [6400/60000]  Loss: 0.000089\n",
      "Train Epoch: 30 [12800/60000]  Loss: 0.000010\n",
      "Train Epoch: 30 [19200/60000]  Loss: 0.000000\n",
      "Train Epoch: 30 [25600/60000]  Loss: 0.000089\n",
      "Train Epoch: 30 [32000/60000]  Loss: 0.000609\n",
      "Train Epoch: 30 [38400/60000]  Loss: 0.000030\n",
      "Train Epoch: 30 [44800/60000]  Loss: 0.000003\n",
      "Train Epoch: 30 [51200/60000]  Loss: 0.000201\n",
      "Train Epoch: 30 [57600/60000]  Loss: 0.000008\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 9913/10000 (99%)\n",
      "\n",
      "Train Epoch: 31 [0/60000]  Loss: 0.000000\n",
      "Train Epoch: 31 [6400/60000]  Loss: 0.000000\n",
      "Train Epoch: 31 [12800/60000]  Loss: 0.000087\n",
      "Train Epoch: 31 [19200/60000]  Loss: 0.000001\n",
      "Train Epoch: 31 [25600/60000]  Loss: 0.000312\n",
      "Train Epoch: 31 [32000/60000]  Loss: 0.000000\n",
      "Train Epoch: 31 [38400/60000]  Loss: 0.000097\n",
      "Train Epoch: 31 [44800/60000]  Loss: 0.000131\n",
      "Train Epoch: 31 [51200/60000]  Loss: 0.000000\n",
      "Train Epoch: 31 [57600/60000]  Loss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 9905/10000 (99%)\n",
      "\n",
      "Train Epoch: 32 [0/60000]  Loss: 0.000000\n",
      "Train Epoch: 32 [6400/60000]  Loss: 0.000000\n",
      "Train Epoch: 32 [12800/60000]  Loss: 0.000007\n",
      "Train Epoch: 32 [19200/60000]  Loss: 0.000045\n",
      "Train Epoch: 32 [25600/60000]  Loss: 0.000011\n",
      "Train Epoch: 32 [32000/60000]  Loss: 0.000875\n",
      "Train Epoch: 32 [38400/60000]  Loss: 0.000132\n",
      "Train Epoch: 32 [44800/60000]  Loss: 0.000000\n",
      "Train Epoch: 32 [51200/60000]  Loss: 0.000002\n",
      "Train Epoch: 32 [57600/60000]  Loss: 0.000001\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 9915/10000 (99%)\n",
      "\n",
      "Train Epoch: 33 [0/60000]  Loss: 0.009031\n",
      "Train Epoch: 33 [6400/60000]  Loss: 0.000006\n",
      "Train Epoch: 33 [12800/60000]  Loss: 0.000149\n",
      "Train Epoch: 33 [19200/60000]  Loss: 0.000000\n",
      "Train Epoch: 33 [25600/60000]  Loss: 0.000000\n",
      "Train Epoch: 33 [32000/60000]  Loss: 0.004858\n",
      "Train Epoch: 33 [38400/60000]  Loss: 0.000008\n",
      "Train Epoch: 33 [44800/60000]  Loss: 0.000586\n",
      "Train Epoch: 33 [51200/60000]  Loss: 0.000000\n",
      "Train Epoch: 33 [57600/60000]  Loss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 9914/10000 (99%)\n",
      "\n",
      "Train Epoch: 34 [0/60000]  Loss: 0.000011\n",
      "Train Epoch: 34 [6400/60000]  Loss: 0.000000\n",
      "Train Epoch: 34 [12800/60000]  Loss: 0.000002\n",
      "Train Epoch: 34 [19200/60000]  Loss: 0.000012\n",
      "Train Epoch: 34 [25600/60000]  Loss: 0.000001\n",
      "Train Epoch: 34 [32000/60000]  Loss: 0.000004\n",
      "Train Epoch: 34 [38400/60000]  Loss: 0.004464\n",
      "Train Epoch: 34 [44800/60000]  Loss: 0.000000\n",
      "Train Epoch: 34 [51200/60000]  Loss: 0.000016\n",
      "Train Epoch: 34 [57600/60000]  Loss: 0.000008\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 9911/10000 (99%)\n",
      "\n",
      "Train Epoch: 35 [0/60000]  Loss: 0.000001\n",
      "Train Epoch: 35 [6400/60000]  Loss: 0.000000\n",
      "Train Epoch: 35 [12800/60000]  Loss: 0.000008\n",
      "Train Epoch: 35 [19200/60000]  Loss: 0.000000\n",
      "Train Epoch: 35 [25600/60000]  Loss: 0.000000\n",
      "Train Epoch: 35 [32000/60000]  Loss: 0.000017\n",
      "Train Epoch: 35 [38400/60000]  Loss: 0.000000\n",
      "Train Epoch: 35 [44800/60000]  Loss: 0.007169\n",
      "Train Epoch: 35 [51200/60000]  Loss: 0.000021\n",
      "Train Epoch: 35 [57600/60000]  Loss: 0.000746\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 9922/10000 (99%)\n",
      "\n",
      "Train Epoch: 36 [0/60000]  Loss: 0.000000\n",
      "Train Epoch: 36 [6400/60000]  Loss: 0.000000\n",
      "Train Epoch: 36 [12800/60000]  Loss: 0.000000\n",
      "Train Epoch: 36 [19200/60000]  Loss: 0.000000\n",
      "Train Epoch: 36 [25600/60000]  Loss: 0.000000\n",
      "Train Epoch: 36 [32000/60000]  Loss: 0.000001\n",
      "Train Epoch: 36 [38400/60000]  Loss: 0.000002\n",
      "Train Epoch: 36 [44800/60000]  Loss: 0.000030\n",
      "Train Epoch: 36 [51200/60000]  Loss: 0.000000\n",
      "Train Epoch: 36 [57600/60000]  Loss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 9925/10000 (99%)\n",
      "\n",
      "Train Epoch: 37 [0/60000]  Loss: 0.000000\n",
      "Train Epoch: 37 [6400/60000]  Loss: 0.000000\n",
      "Train Epoch: 37 [12800/60000]  Loss: 0.000001\n",
      "Train Epoch: 37 [19200/60000]  Loss: 0.000651\n",
      "Train Epoch: 37 [25600/60000]  Loss: 0.000001\n",
      "Train Epoch: 37 [32000/60000]  Loss: 0.000002\n",
      "Train Epoch: 37 [38400/60000]  Loss: 0.000001\n",
      "Train Epoch: 37 [44800/60000]  Loss: 0.000004\n",
      "Train Epoch: 37 [51200/60000]  Loss: 0.000004\n",
      "Train Epoch: 37 [57600/60000]  Loss: 0.000005\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 9907/10000 (99%)\n",
      "\n",
      "Train Epoch: 38 [0/60000]  Loss: 0.002570\n",
      "Train Epoch: 38 [6400/60000]  Loss: 0.000036\n",
      "Train Epoch: 38 [12800/60000]  Loss: 0.000000\n",
      "Train Epoch: 38 [19200/60000]  Loss: 0.000001\n",
      "Train Epoch: 38 [25600/60000]  Loss: 0.000001\n",
      "Train Epoch: 38 [32000/60000]  Loss: 0.000000\n",
      "Train Epoch: 38 [38400/60000]  Loss: 0.098547\n",
      "Train Epoch: 38 [44800/60000]  Loss: 0.000000\n",
      "Train Epoch: 38 [51200/60000]  Loss: 0.000000\n",
      "Train Epoch: 38 [57600/60000]  Loss: 0.002781\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 9920/10000 (99%)\n",
      "\n",
      "Train Epoch: 39 [0/60000]  Loss: 0.007873\n",
      "Train Epoch: 39 [6400/60000]  Loss: 0.000000\n",
      "Train Epoch: 39 [12800/60000]  Loss: 0.000000\n",
      "Train Epoch: 39 [19200/60000]  Loss: 0.000000\n",
      "Train Epoch: 39 [25600/60000]  Loss: 0.000000\n",
      "Train Epoch: 39 [32000/60000]  Loss: 0.000000\n",
      "Train Epoch: 39 [38400/60000]  Loss: 0.000001\n",
      "Train Epoch: 39 [44800/60000]  Loss: 0.000020\n",
      "Train Epoch: 39 [51200/60000]  Loss: 0.000000\n",
      "Train Epoch: 39 [57600/60000]  Loss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 9926/10000 (99%)\n",
      "\n",
      "Train Epoch: 40 [0/60000]  Loss: 0.000000\n",
      "Train Epoch: 40 [6400/60000]  Loss: 0.003015\n",
      "Train Epoch: 40 [12800/60000]  Loss: 0.000029\n",
      "Train Epoch: 40 [19200/60000]  Loss: 0.000000\n",
      "Train Epoch: 40 [25600/60000]  Loss: 0.008841\n",
      "Train Epoch: 40 [32000/60000]  Loss: 0.005448\n",
      "Train Epoch: 40 [38400/60000]  Loss: 0.000010\n",
      "Train Epoch: 40 [44800/60000]  Loss: 0.000135\n",
      "Train Epoch: 40 [51200/60000]  Loss: 0.000000\n",
      "Train Epoch: 40 [57600/60000]  Loss: 0.000032\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 9919/10000 (99%)\n",
      "\n",
      "Train Epoch: 41 [0/60000]  Loss: 0.000000\n",
      "Train Epoch: 41 [6400/60000]  Loss: 0.000000\n",
      "Train Epoch: 41 [12800/60000]  Loss: 0.000000\n",
      "Train Epoch: 41 [19200/60000]  Loss: 0.000041\n",
      "Train Epoch: 41 [25600/60000]  Loss: 0.000002\n",
      "Train Epoch: 41 [32000/60000]  Loss: 0.000133\n",
      "Train Epoch: 41 [38400/60000]  Loss: 0.000000\n",
      "Train Epoch: 41 [44800/60000]  Loss: 0.000000\n",
      "Train Epoch: 41 [51200/60000]  Loss: 0.000015\n",
      "Train Epoch: 41 [57600/60000]  Loss: 0.008984\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 9887/10000 (99%)\n",
      "\n",
      "Train Epoch: 42 [0/60000]  Loss: 0.027045\n",
      "Train Epoch: 42 [6400/60000]  Loss: 0.000001\n",
      "Train Epoch: 42 [12800/60000]  Loss: 0.000000\n",
      "Train Epoch: 42 [19200/60000]  Loss: 0.000103\n",
      "Train Epoch: 42 [25600/60000]  Loss: 0.000000\n",
      "Train Epoch: 42 [32000/60000]  Loss: 0.000000\n",
      "Train Epoch: 42 [38400/60000]  Loss: 0.000004\n",
      "Train Epoch: 42 [44800/60000]  Loss: 0.000000\n",
      "Train Epoch: 42 [51200/60000]  Loss: 0.000021\n",
      "Train Epoch: 42 [57600/60000]  Loss: 0.000168\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 9908/10000 (99%)\n",
      "\n",
      "Train Epoch: 43 [0/60000]  Loss: 0.000001\n",
      "Train Epoch: 43 [6400/60000]  Loss: 0.000001\n",
      "Train Epoch: 43 [12800/60000]  Loss: 0.000000\n",
      "Train Epoch: 43 [19200/60000]  Loss: 0.000000\n",
      "Train Epoch: 43 [25600/60000]  Loss: 0.000000\n",
      "Train Epoch: 43 [32000/60000]  Loss: 0.000008\n",
      "Train Epoch: 43 [38400/60000]  Loss: 0.000000\n",
      "Train Epoch: 43 [44800/60000]  Loss: 0.000000\n",
      "Train Epoch: 43 [51200/60000]  Loss: 0.000006\n",
      "Train Epoch: 43 [57600/60000]  Loss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 9933/10000 (99%)\n",
      "\n",
      "Train Epoch: 44 [0/60000]  Loss: 0.000001\n",
      "Train Epoch: 44 [6400/60000]  Loss: 0.000746\n",
      "Train Epoch: 44 [12800/60000]  Loss: 0.000000\n",
      "Train Epoch: 44 [19200/60000]  Loss: 0.000001\n",
      "Train Epoch: 44 [25600/60000]  Loss: 0.000001\n",
      "Train Epoch: 44 [32000/60000]  Loss: 0.000000\n",
      "Train Epoch: 44 [38400/60000]  Loss: 0.000000\n",
      "Train Epoch: 44 [44800/60000]  Loss: 0.000000\n",
      "Train Epoch: 44 [51200/60000]  Loss: 0.000000\n",
      "Train Epoch: 44 [57600/60000]  Loss: 0.000001\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 9906/10000 (99%)\n",
      "\n",
      "Train Epoch: 45 [0/60000]  Loss: 0.028425\n",
      "Train Epoch: 45 [6400/60000]  Loss: 0.000000\n",
      "Train Epoch: 45 [12800/60000]  Loss: 0.000000\n",
      "Train Epoch: 45 [19200/60000]  Loss: 0.000000\n",
      "Train Epoch: 45 [25600/60000]  Loss: 0.000000\n",
      "Train Epoch: 45 [32000/60000]  Loss: 0.000000\n",
      "Train Epoch: 45 [38400/60000]  Loss: 0.000000\n",
      "Train Epoch: 45 [44800/60000]  Loss: 0.000000\n",
      "Train Epoch: 45 [51200/60000]  Loss: 0.000000\n",
      "Train Epoch: 45 [57600/60000]  Loss: 0.000005\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 9921/10000 (99%)\n",
      "\n",
      "Train Epoch: 46 [0/60000]  Loss: 0.000000\n",
      "Train Epoch: 46 [6400/60000]  Loss: 0.006346\n",
      "Train Epoch: 46 [12800/60000]  Loss: 0.113055\n",
      "Train Epoch: 46 [19200/60000]  Loss: 0.000074\n",
      "Train Epoch: 46 [25600/60000]  Loss: 0.000001\n",
      "Train Epoch: 46 [32000/60000]  Loss: 0.000001\n",
      "Train Epoch: 46 [38400/60000]  Loss: 0.000000\n",
      "Train Epoch: 46 [44800/60000]  Loss: 0.000008\n",
      "Train Epoch: 46 [51200/60000]  Loss: 0.000040\n",
      "Train Epoch: 46 [57600/60000]  Loss: 0.000001\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 9925/10000 (99%)\n",
      "\n",
      "Train Epoch: 47 [0/60000]  Loss: 0.000000\n",
      "Train Epoch: 47 [6400/60000]  Loss: 0.000001\n",
      "Train Epoch: 47 [12800/60000]  Loss: 0.000096\n",
      "Train Epoch: 47 [19200/60000]  Loss: 0.000000\n",
      "Train Epoch: 47 [25600/60000]  Loss: 0.000000\n",
      "Train Epoch: 47 [32000/60000]  Loss: 0.000172\n",
      "Train Epoch: 47 [38400/60000]  Loss: 0.000004\n",
      "Train Epoch: 47 [44800/60000]  Loss: 0.000000\n",
      "Train Epoch: 47 [51200/60000]  Loss: 0.000000\n",
      "Train Epoch: 47 [57600/60000]  Loss: 0.000033\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 9924/10000 (99%)\n",
      "\n",
      "Train Epoch: 48 [0/60000]  Loss: 0.000002\n",
      "Train Epoch: 48 [6400/60000]  Loss: 0.000001\n",
      "Train Epoch: 48 [12800/60000]  Loss: 0.000005\n",
      "Train Epoch: 48 [19200/60000]  Loss: 0.000000\n",
      "Train Epoch: 48 [25600/60000]  Loss: 0.000001\n",
      "Train Epoch: 48 [32000/60000]  Loss: 0.000000\n",
      "Train Epoch: 48 [38400/60000]  Loss: 0.000000\n",
      "Train Epoch: 48 [44800/60000]  Loss: 0.000000\n",
      "Train Epoch: 48 [51200/60000]  Loss: 0.000002\n",
      "Train Epoch: 48 [57600/60000]  Loss: 0.000002\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 9915/10000 (99%)\n",
      "\n",
      "Train Epoch: 49 [0/60000]  Loss: 0.003680\n",
      "Train Epoch: 49 [6400/60000]  Loss: 0.000003\n",
      "Train Epoch: 49 [12800/60000]  Loss: 0.000000\n",
      "Train Epoch: 49 [19200/60000]  Loss: 0.032777\n",
      "Train Epoch: 49 [25600/60000]  Loss: 0.000119\n",
      "Train Epoch: 49 [32000/60000]  Loss: 0.000634\n",
      "Train Epoch: 49 [38400/60000]  Loss: 0.000000\n",
      "Train Epoch: 49 [44800/60000]  Loss: 0.004175\n",
      "Train Epoch: 49 [51200/60000]  Loss: 0.000000\n",
      "Train Epoch: 49 [57600/60000]  Loss: 0.000824\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 9918/10000 (99%)\n",
      "\n",
      "Train Epoch: 50 [0/60000]  Loss: 0.000000\n",
      "Train Epoch: 50 [6400/60000]  Loss: 0.000150\n",
      "Train Epoch: 50 [12800/60000]  Loss: 0.000000\n",
      "Train Epoch: 50 [19200/60000]  Loss: 0.000000\n",
      "Train Epoch: 50 [25600/60000]  Loss: 0.000001\n",
      "Train Epoch: 50 [32000/60000]  Loss: 0.000011\n",
      "Train Epoch: 50 [38400/60000]  Loss: 0.000000\n",
      "Train Epoch: 50 [44800/60000]  Loss: 0.000000\n",
      "Train Epoch: 50 [51200/60000]  Loss: 0.000000\n",
      "Train Epoch: 50 [57600/60000]  Loss: 0.000003\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 9923/10000 (99%)\n",
      "\n",
      "Train Epoch: 51 [0/60000]  Loss: 0.000002\n",
      "Train Epoch: 51 [6400/60000]  Loss: 0.000001\n",
      "Train Epoch: 51 [12800/60000]  Loss: 0.000000\n",
      "Train Epoch: 51 [19200/60000]  Loss: 0.000002\n",
      "Train Epoch: 51 [25600/60000]  Loss: 0.000000\n",
      "Train Epoch: 51 [32000/60000]  Loss: 0.000000\n",
      "Train Epoch: 51 [38400/60000]  Loss: 0.000003\n",
      "Train Epoch: 51 [44800/60000]  Loss: 0.000000\n",
      "Train Epoch: 51 [51200/60000]  Loss: 0.000001\n",
      "Train Epoch: 51 [57600/60000]  Loss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 9919/10000 (99%)\n",
      "\n",
      "Train Epoch: 52 [0/60000]  Loss: 0.000000\n",
      "Train Epoch: 52 [6400/60000]  Loss: 0.000021\n",
      "Train Epoch: 52 [12800/60000]  Loss: 0.000000\n",
      "Train Epoch: 52 [19200/60000]  Loss: 0.002189\n",
      "Train Epoch: 52 [25600/60000]  Loss: 0.000016\n",
      "Train Epoch: 52 [32000/60000]  Loss: 0.000006\n",
      "Train Epoch: 52 [38400/60000]  Loss: 0.000001\n",
      "Train Epoch: 52 [44800/60000]  Loss: 0.000000\n",
      "Train Epoch: 52 [51200/60000]  Loss: 0.000021\n",
      "Train Epoch: 52 [57600/60000]  Loss: 0.018526\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 9910/10000 (99%)\n",
      "\n",
      "Train Epoch: 53 [0/60000]  Loss: 0.000000\n",
      "Train Epoch: 53 [6400/60000]  Loss: 0.000000\n",
      "Train Epoch: 53 [12800/60000]  Loss: 0.000001\n",
      "Train Epoch: 53 [19200/60000]  Loss: 0.000000\n",
      "Train Epoch: 53 [25600/60000]  Loss: 0.000000\n",
      "Train Epoch: 53 [32000/60000]  Loss: 0.000000\n",
      "Train Epoch: 53 [38400/60000]  Loss: 0.000000\n",
      "Train Epoch: 53 [44800/60000]  Loss: 0.000000\n",
      "Train Epoch: 53 [51200/60000]  Loss: 0.000000\n",
      "Train Epoch: 53 [57600/60000]  Loss: 0.020863\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 9905/10000 (99%)\n",
      "\n",
      "Train Epoch: 54 [0/60000]  Loss: 0.000000\n",
      "Train Epoch: 54 [6400/60000]  Loss: 0.000000\n",
      "Train Epoch: 54 [12800/60000]  Loss: 0.000000\n",
      "Train Epoch: 54 [19200/60000]  Loss: 0.000000\n",
      "Train Epoch: 54 [25600/60000]  Loss: 0.000002\n",
      "Train Epoch: 54 [32000/60000]  Loss: 0.000105\n",
      "Train Epoch: 54 [38400/60000]  Loss: 0.000000\n",
      "Train Epoch: 54 [44800/60000]  Loss: 0.000000\n",
      "Train Epoch: 54 [51200/60000]  Loss: 0.000000\n",
      "Train Epoch: 54 [57600/60000]  Loss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 9918/10000 (99%)\n",
      "\n",
      "Train Epoch: 55 [0/60000]  Loss: 0.000000\n",
      "Train Epoch: 55 [6400/60000]  Loss: 0.000000\n",
      "Train Epoch: 55 [12800/60000]  Loss: 0.000000\n",
      "Train Epoch: 55 [19200/60000]  Loss: 0.000001\n",
      "Train Epoch: 55 [25600/60000]  Loss: 0.000002\n",
      "Train Epoch: 55 [32000/60000]  Loss: 0.000000\n",
      "Train Epoch: 55 [38400/60000]  Loss: 0.000000\n",
      "Train Epoch: 55 [44800/60000]  Loss: 0.000000\n",
      "Train Epoch: 55 [51200/60000]  Loss: 0.000028\n",
      "Train Epoch: 55 [57600/60000]  Loss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 9911/10000 (99%)\n",
      "\n",
      "Train Epoch: 56 [0/60000]  Loss: 0.000000\n",
      "Train Epoch: 56 [6400/60000]  Loss: 0.000000\n",
      "Train Epoch: 56 [12800/60000]  Loss: 0.000000\n",
      "Train Epoch: 56 [19200/60000]  Loss: 0.000002\n",
      "Train Epoch: 56 [25600/60000]  Loss: 0.000000\n",
      "Train Epoch: 56 [32000/60000]  Loss: 0.000000\n",
      "Train Epoch: 56 [38400/60000]  Loss: 0.000000\n",
      "Train Epoch: 56 [44800/60000]  Loss: 0.000000\n",
      "Train Epoch: 56 [51200/60000]  Loss: 0.000022\n",
      "Train Epoch: 56 [57600/60000]  Loss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 9920/10000 (99%)\n",
      "\n",
      "Train Epoch: 57 [0/60000]  Loss: 0.000000\n",
      "Train Epoch: 57 [6400/60000]  Loss: 0.000000\n",
      "Train Epoch: 57 [12800/60000]  Loss: 0.000000\n",
      "Train Epoch: 57 [19200/60000]  Loss: 0.000000\n",
      "Train Epoch: 57 [25600/60000]  Loss: 0.000000\n",
      "Train Epoch: 57 [32000/60000]  Loss: 0.000004\n",
      "Train Epoch: 57 [38400/60000]  Loss: 0.000000\n",
      "Train Epoch: 57 [44800/60000]  Loss: 0.188461\n",
      "Train Epoch: 57 [51200/60000]  Loss: 0.000000\n",
      "Train Epoch: 57 [57600/60000]  Loss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 9925/10000 (99%)\n",
      "\n",
      "Train Epoch: 58 [0/60000]  Loss: 0.020387\n",
      "Train Epoch: 58 [6400/60000]  Loss: 0.000000\n",
      "Train Epoch: 58 [12800/60000]  Loss: 0.000000\n",
      "Train Epoch: 58 [19200/60000]  Loss: 0.000000\n",
      "Train Epoch: 58 [25600/60000]  Loss: 0.000000\n",
      "Train Epoch: 58 [32000/60000]  Loss: 0.003374\n",
      "Train Epoch: 58 [38400/60000]  Loss: 0.000004\n",
      "Train Epoch: 58 [44800/60000]  Loss: 0.000000\n",
      "Train Epoch: 58 [51200/60000]  Loss: 0.000000\n",
      "Train Epoch: 58 [57600/60000]  Loss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 9914/10000 (99%)\n",
      "\n",
      "Train Epoch: 59 [0/60000]  Loss: 0.000000\n",
      "Train Epoch: 59 [6400/60000]  Loss: 0.000087\n",
      "Train Epoch: 59 [12800/60000]  Loss: 0.000000\n",
      "Train Epoch: 59 [19200/60000]  Loss: 0.000000\n",
      "Train Epoch: 59 [25600/60000]  Loss: 0.000000\n",
      "Train Epoch: 59 [32000/60000]  Loss: 0.000000\n",
      "Train Epoch: 59 [38400/60000]  Loss: 0.000000\n",
      "Train Epoch: 59 [44800/60000]  Loss: 0.000000\n",
      "Train Epoch: 59 [51200/60000]  Loss: 0.000000\n",
      "Train Epoch: 59 [57600/60000]  Loss: 0.000004\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 9905/10000 (99%)\n",
      "\n",
      "Train Epoch: 60 [0/60000]  Loss: 0.000000\n",
      "Train Epoch: 60 [6400/60000]  Loss: 0.000000\n",
      "Train Epoch: 60 [12800/60000]  Loss: 0.000000\n",
      "Train Epoch: 60 [19200/60000]  Loss: 0.000003\n",
      "Train Epoch: 60 [25600/60000]  Loss: 0.000000\n",
      "Train Epoch: 60 [32000/60000]  Loss: 0.000000\n",
      "Train Epoch: 60 [38400/60000]  Loss: 0.000000\n",
      "Train Epoch: 60 [44800/60000]  Loss: 0.000000\n",
      "Train Epoch: 60 [51200/60000]  Loss: 0.004050\n",
      "Train Epoch: 60 [57600/60000]  Loss: 0.068543\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 9910/10000 (99%)\n",
      "\n",
      "Train Epoch: 61 [0/60000]  Loss: 0.000000\n",
      "Train Epoch: 61 [6400/60000]  Loss: 0.000127\n",
      "Train Epoch: 61 [12800/60000]  Loss: 0.000007\n",
      "Train Epoch: 61 [19200/60000]  Loss: 0.000000\n",
      "Train Epoch: 61 [25600/60000]  Loss: 0.000000\n",
      "Train Epoch: 61 [32000/60000]  Loss: 0.000000\n",
      "Train Epoch: 61 [38400/60000]  Loss: 0.000000\n",
      "Train Epoch: 61 [44800/60000]  Loss: 0.000009\n",
      "Train Epoch: 61 [51200/60000]  Loss: 0.000000\n",
      "Train Epoch: 61 [57600/60000]  Loss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 9905/10000 (99%)\n",
      "\n",
      "Train Epoch: 62 [0/60000]  Loss: 0.000000\n",
      "Train Epoch: 62 [6400/60000]  Loss: 0.000005\n",
      "Train Epoch: 62 [12800/60000]  Loss: 0.000001\n",
      "Train Epoch: 62 [19200/60000]  Loss: 0.000002\n",
      "Train Epoch: 62 [25600/60000]  Loss: 0.000000\n",
      "Train Epoch: 62 [32000/60000]  Loss: 0.000000\n",
      "Train Epoch: 62 [38400/60000]  Loss: 0.000106\n",
      "Train Epoch: 62 [44800/60000]  Loss: 0.000009\n",
      "Train Epoch: 62 [51200/60000]  Loss: 0.000000\n",
      "Train Epoch: 62 [57600/60000]  Loss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 9902/10000 (99%)\n",
      "\n",
      "Train Epoch: 63 [0/60000]  Loss: 0.000000\n",
      "Train Epoch: 63 [6400/60000]  Loss: 0.000000\n",
      "Train Epoch: 63 [12800/60000]  Loss: 0.000000\n",
      "Train Epoch: 63 [19200/60000]  Loss: 0.000000\n",
      "Train Epoch: 63 [25600/60000]  Loss: 0.000000\n",
      "Train Epoch: 63 [32000/60000]  Loss: 0.041756\n",
      "Train Epoch: 63 [38400/60000]  Loss: 0.000159\n",
      "Train Epoch: 63 [44800/60000]  Loss: 0.000000\n",
      "Train Epoch: 63 [51200/60000]  Loss: 0.000000\n",
      "Train Epoch: 63 [57600/60000]  Loss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 9908/10000 (99%)\n",
      "\n",
      "Train Epoch: 64 [0/60000]  Loss: 0.000000\n",
      "Train Epoch: 64 [6400/60000]  Loss: 0.000003\n",
      "Train Epoch: 64 [12800/60000]  Loss: 0.000000\n",
      "Train Epoch: 64 [19200/60000]  Loss: 0.004976\n",
      "Train Epoch: 64 [25600/60000]  Loss: 0.000000\n",
      "Train Epoch: 64 [32000/60000]  Loss: 0.000043\n",
      "Train Epoch: 64 [38400/60000]  Loss: 0.000000\n",
      "Train Epoch: 64 [44800/60000]  Loss: 0.000000\n",
      "Train Epoch: 64 [51200/60000]  Loss: 0.000000\n",
      "Train Epoch: 64 [57600/60000]  Loss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 9920/10000 (99%)\n",
      "\n",
      "Train Epoch: 65 [0/60000]  Loss: 0.000000\n",
      "Train Epoch: 65 [6400/60000]  Loss: 0.000000\n",
      "Train Epoch: 65 [12800/60000]  Loss: 0.000000\n",
      "Train Epoch: 65 [19200/60000]  Loss: 0.000001\n",
      "Train Epoch: 65 [25600/60000]  Loss: 0.000000\n",
      "Train Epoch: 65 [32000/60000]  Loss: 0.000000\n",
      "Train Epoch: 65 [38400/60000]  Loss: 0.000006\n",
      "Train Epoch: 65 [44800/60000]  Loss: 0.000000\n",
      "Train Epoch: 65 [51200/60000]  Loss: 0.000762\n",
      "Train Epoch: 65 [57600/60000]  Loss: 0.000008\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 9919/10000 (99%)\n",
      "\n",
      "Train Epoch: 66 [0/60000]  Loss: 0.045047\n",
      "Train Epoch: 66 [6400/60000]  Loss: 0.000000\n",
      "Train Epoch: 66 [12800/60000]  Loss: 0.000000\n",
      "Train Epoch: 66 [19200/60000]  Loss: 0.000000\n",
      "Train Epoch: 66 [25600/60000]  Loss: 0.000000\n",
      "Train Epoch: 66 [32000/60000]  Loss: 0.000000\n",
      "Train Epoch: 66 [38400/60000]  Loss: 0.000000\n",
      "Train Epoch: 66 [44800/60000]  Loss: 0.000000\n",
      "Train Epoch: 66 [51200/60000]  Loss: 0.000000\n",
      "Train Epoch: 66 [57600/60000]  Loss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 9903/10000 (99%)\n",
      "\n",
      "Train Epoch: 67 [0/60000]  Loss: 0.000002\n",
      "Train Epoch: 67 [6400/60000]  Loss: 0.000000\n",
      "Train Epoch: 67 [12800/60000]  Loss: 0.000000\n",
      "Train Epoch: 67 [19200/60000]  Loss: 0.000000\n",
      "Train Epoch: 67 [25600/60000]  Loss: 0.000000\n",
      "Train Epoch: 67 [32000/60000]  Loss: 0.003435\n",
      "Train Epoch: 67 [38400/60000]  Loss: 0.000000\n",
      "Train Epoch: 67 [44800/60000]  Loss: 0.000000\n",
      "Train Epoch: 67 [51200/60000]  Loss: 0.000000\n",
      "Train Epoch: 67 [57600/60000]  Loss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 9925/10000 (99%)\n",
      "\n",
      "Train Epoch: 68 [0/60000]  Loss: 0.000000\n",
      "Train Epoch: 68 [6400/60000]  Loss: 0.000000\n",
      "Train Epoch: 68 [12800/60000]  Loss: 0.000003\n",
      "Train Epoch: 68 [19200/60000]  Loss: 0.000000\n",
      "Train Epoch: 68 [25600/60000]  Loss: 0.000096\n",
      "Train Epoch: 68 [32000/60000]  Loss: 0.000000\n",
      "Train Epoch: 68 [38400/60000]  Loss: 0.000000\n",
      "Train Epoch: 68 [44800/60000]  Loss: 0.000003\n",
      "Train Epoch: 68 [51200/60000]  Loss: 0.001435\n",
      "Train Epoch: 68 [57600/60000]  Loss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 9922/10000 (99%)\n",
      "\n",
      "Train Epoch: 69 [0/60000]  Loss: 0.000000\n",
      "Train Epoch: 69 [6400/60000]  Loss: 0.000001\n",
      "Train Epoch: 69 [12800/60000]  Loss: 0.000032\n",
      "Train Epoch: 69 [19200/60000]  Loss: 0.000000\n",
      "Train Epoch: 69 [25600/60000]  Loss: 0.000938\n",
      "Train Epoch: 69 [32000/60000]  Loss: 0.000000\n",
      "Train Epoch: 69 [38400/60000]  Loss: 0.000000\n",
      "Train Epoch: 69 [44800/60000]  Loss: 0.000000\n",
      "Train Epoch: 69 [51200/60000]  Loss: 0.000000\n",
      "Train Epoch: 69 [57600/60000]  Loss: 0.000132\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 9917/10000 (99%)\n",
      "\n",
      "Train Epoch: 70 [0/60000]  Loss: 0.000000\n",
      "Train Epoch: 70 [6400/60000]  Loss: 0.000000\n",
      "Train Epoch: 70 [12800/60000]  Loss: 0.000000\n",
      "Train Epoch: 70 [19200/60000]  Loss: 0.000000\n",
      "Train Epoch: 70 [25600/60000]  Loss: 0.000000\n",
      "Train Epoch: 70 [32000/60000]  Loss: 0.000000\n",
      "Train Epoch: 70 [38400/60000]  Loss: 0.000000\n",
      "Train Epoch: 70 [44800/60000]  Loss: 0.000001\n",
      "Train Epoch: 70 [51200/60000]  Loss: 0.000000\n",
      "Train Epoch: 70 [57600/60000]  Loss: 0.000002\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 9920/10000 (99%)\n",
      "\n",
      "Train Epoch: 71 [0/60000]  Loss: 0.000000\n",
      "Train Epoch: 71 [6400/60000]  Loss: 0.000000\n",
      "Train Epoch: 71 [12800/60000]  Loss: 0.000000\n",
      "Train Epoch: 71 [19200/60000]  Loss: 0.000000\n",
      "Train Epoch: 71 [25600/60000]  Loss: 0.000000\n",
      "Train Epoch: 71 [32000/60000]  Loss: 0.000000\n",
      "Train Epoch: 71 [38400/60000]  Loss: 0.000000\n",
      "Train Epoch: 71 [44800/60000]  Loss: 0.000000\n",
      "Train Epoch: 71 [51200/60000]  Loss: 0.000000\n",
      "Train Epoch: 71 [57600/60000]  Loss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 9919/10000 (99%)\n",
      "\n",
      "Train Epoch: 72 [0/60000]  Loss: 0.000000\n",
      "Train Epoch: 72 [6400/60000]  Loss: 0.000000\n",
      "Train Epoch: 72 [12800/60000]  Loss: 0.000000\n",
      "Train Epoch: 72 [19200/60000]  Loss: 0.000000\n",
      "Train Epoch: 72 [25600/60000]  Loss: 0.000000\n",
      "Train Epoch: 72 [32000/60000]  Loss: 0.000000\n",
      "Train Epoch: 72 [38400/60000]  Loss: 0.000000\n",
      "Train Epoch: 72 [44800/60000]  Loss: 0.000000\n",
      "Train Epoch: 72 [51200/60000]  Loss: 0.000000\n",
      "Train Epoch: 72 [57600/60000]  Loss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 9918/10000 (99%)\n",
      "\n",
      "Train Epoch: 73 [0/60000]  Loss: 0.000000\n",
      "Train Epoch: 73 [6400/60000]  Loss: 0.000001\n",
      "Train Epoch: 73 [12800/60000]  Loss: 0.000000\n",
      "Train Epoch: 73 [19200/60000]  Loss: 0.000000\n",
      "Train Epoch: 73 [25600/60000]  Loss: 0.000000\n",
      "Train Epoch: 73 [32000/60000]  Loss: 0.000000\n",
      "Train Epoch: 73 [38400/60000]  Loss: 0.000000\n",
      "Train Epoch: 73 [44800/60000]  Loss: 0.000000\n",
      "Train Epoch: 73 [51200/60000]  Loss: 0.000000\n",
      "Train Epoch: 73 [57600/60000]  Loss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 9905/10000 (99%)\n",
      "\n",
      "Train Epoch: 74 [0/60000]  Loss: 0.000000\n",
      "Train Epoch: 74 [6400/60000]  Loss: 0.000000\n",
      "Train Epoch: 74 [12800/60000]  Loss: 0.000000\n",
      "Train Epoch: 74 [19200/60000]  Loss: 0.000000\n",
      "Train Epoch: 74 [25600/60000]  Loss: 0.000000\n",
      "Train Epoch: 74 [32000/60000]  Loss: 0.000000\n",
      "Train Epoch: 74 [38400/60000]  Loss: 0.000000\n",
      "Train Epoch: 74 [44800/60000]  Loss: 0.000000\n",
      "Train Epoch: 74 [51200/60000]  Loss: 0.000000\n",
      "Train Epoch: 74 [57600/60000]  Loss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 9915/10000 (99%)\n",
      "\n",
      "Train Epoch: 75 [0/60000]  Loss: 0.000000\n",
      "Train Epoch: 75 [6400/60000]  Loss: 0.000404\n",
      "Train Epoch: 75 [12800/60000]  Loss: 0.000001\n",
      "Train Epoch: 75 [19200/60000]  Loss: 0.000000\n",
      "Train Epoch: 75 [25600/60000]  Loss: 0.000299\n",
      "Train Epoch: 75 [32000/60000]  Loss: 0.000000\n",
      "Train Epoch: 75 [38400/60000]  Loss: 0.000000\n",
      "Train Epoch: 75 [44800/60000]  Loss: 0.000000\n",
      "Train Epoch: 75 [51200/60000]  Loss: 0.000257\n",
      "Train Epoch: 75 [57600/60000]  Loss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 9919/10000 (99%)\n",
      "\n",
      "Train Epoch: 76 [0/60000]  Loss: 0.000000\n",
      "Train Epoch: 76 [6400/60000]  Loss: 0.000000\n",
      "Train Epoch: 76 [12800/60000]  Loss: 0.000000\n",
      "Train Epoch: 76 [19200/60000]  Loss: 0.000000\n",
      "Train Epoch: 76 [25600/60000]  Loss: 0.000000\n",
      "Train Epoch: 76 [32000/60000]  Loss: 0.000001\n",
      "Train Epoch: 76 [38400/60000]  Loss: 0.000003\n",
      "Train Epoch: 76 [44800/60000]  Loss: 0.000000\n",
      "Train Epoch: 76 [51200/60000]  Loss: 0.004467\n",
      "Train Epoch: 76 [57600/60000]  Loss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 9931/10000 (99%)\n",
      "\n",
      "Train Epoch: 77 [0/60000]  Loss: 0.000000\n",
      "Train Epoch: 77 [6400/60000]  Loss: 0.000000\n",
      "Train Epoch: 77 [12800/60000]  Loss: 0.000000\n",
      "Train Epoch: 77 [19200/60000]  Loss: 0.000000\n",
      "Train Epoch: 77 [25600/60000]  Loss: 0.000000\n",
      "Train Epoch: 77 [32000/60000]  Loss: 0.000000\n",
      "Train Epoch: 77 [38400/60000]  Loss: 0.000000\n",
      "Train Epoch: 77 [44800/60000]  Loss: 0.000000\n",
      "Train Epoch: 77 [51200/60000]  Loss: 0.000000\n",
      "Train Epoch: 77 [57600/60000]  Loss: 0.000001\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 9923/10000 (99%)\n",
      "\n",
      "Train Epoch: 78 [0/60000]  Loss: 0.000011\n",
      "Train Epoch: 78 [6400/60000]  Loss: 0.000000\n",
      "Train Epoch: 78 [12800/60000]  Loss: 0.000000\n",
      "Train Epoch: 78 [19200/60000]  Loss: 0.000000\n",
      "Train Epoch: 78 [25600/60000]  Loss: 0.000000\n",
      "Train Epoch: 78 [32000/60000]  Loss: 0.000000\n",
      "Train Epoch: 78 [38400/60000]  Loss: 0.000000\n",
      "Train Epoch: 78 [44800/60000]  Loss: 0.000000\n",
      "Train Epoch: 78 [51200/60000]  Loss: 0.000000\n",
      "Train Epoch: 78 [57600/60000]  Loss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 9927/10000 (99%)\n",
      "\n",
      "Train Epoch: 79 [0/60000]  Loss: 0.000000\n",
      "Train Epoch: 79 [6400/60000]  Loss: 0.000000\n",
      "Train Epoch: 79 [12800/60000]  Loss: 0.000000\n",
      "Train Epoch: 79 [19200/60000]  Loss: 0.000000\n",
      "Train Epoch: 79 [25600/60000]  Loss: 0.000000\n",
      "Train Epoch: 79 [32000/60000]  Loss: 0.000000\n",
      "Train Epoch: 79 [38400/60000]  Loss: 0.000000\n",
      "Train Epoch: 79 [44800/60000]  Loss: 0.000000\n",
      "Train Epoch: 79 [51200/60000]  Loss: 0.000000\n",
      "Train Epoch: 79 [57600/60000]  Loss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 9919/10000 (99%)\n",
      "\n",
      "Train Epoch: 80 [0/60000]  Loss: 0.000000\n",
      "Train Epoch: 80 [6400/60000]  Loss: 0.000000\n",
      "Train Epoch: 80 [12800/60000]  Loss: 0.000003\n",
      "Train Epoch: 80 [19200/60000]  Loss: 0.003171\n",
      "Train Epoch: 80 [25600/60000]  Loss: 0.000000\n",
      "Train Epoch: 80 [32000/60000]  Loss: 0.000000\n",
      "Train Epoch: 80 [38400/60000]  Loss: 0.000000\n",
      "Train Epoch: 80 [44800/60000]  Loss: 0.000000\n",
      "Train Epoch: 80 [51200/60000]  Loss: 0.000000\n",
      "Train Epoch: 80 [57600/60000]  Loss: 0.000004\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 9927/10000 (99%)\n",
      "\n",
      "Train Epoch: 81 [0/60000]  Loss: 0.000000\n",
      "Train Epoch: 81 [6400/60000]  Loss: 0.000000\n",
      "Train Epoch: 81 [12800/60000]  Loss: 0.000000\n",
      "Train Epoch: 81 [19200/60000]  Loss: 0.000000\n",
      "Train Epoch: 81 [25600/60000]  Loss: 0.000000\n",
      "Train Epoch: 81 [32000/60000]  Loss: 0.000029\n",
      "Train Epoch: 81 [38400/60000]  Loss: 0.000000\n",
      "Train Epoch: 81 [44800/60000]  Loss: 0.000000\n",
      "Train Epoch: 81 [51200/60000]  Loss: 0.000000\n",
      "Train Epoch: 81 [57600/60000]  Loss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 9929/10000 (99%)\n",
      "\n",
      "Train Epoch: 82 [0/60000]  Loss: 0.000000\n",
      "Train Epoch: 82 [6400/60000]  Loss: 0.000000\n",
      "Train Epoch: 82 [12800/60000]  Loss: 0.000000\n",
      "Train Epoch: 82 [19200/60000]  Loss: 0.000000\n",
      "Train Epoch: 82 [25600/60000]  Loss: 0.000000\n",
      "Train Epoch: 82 [32000/60000]  Loss: 0.000000\n",
      "Train Epoch: 82 [38400/60000]  Loss: 0.000000\n",
      "Train Epoch: 82 [44800/60000]  Loss: 0.000000\n",
      "Train Epoch: 82 [51200/60000]  Loss: 0.093123\n",
      "Train Epoch: 82 [57600/60000]  Loss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 9923/10000 (99%)\n",
      "\n",
      "Train Epoch: 83 [0/60000]  Loss: 0.000000\n",
      "Train Epoch: 83 [6400/60000]  Loss: 0.000000\n",
      "Train Epoch: 83 [12800/60000]  Loss: 0.000000\n",
      "Train Epoch: 83 [19200/60000]  Loss: 0.000015\n",
      "Train Epoch: 83 [25600/60000]  Loss: 0.000000\n",
      "Train Epoch: 83 [32000/60000]  Loss: 0.000000\n",
      "Train Epoch: 83 [38400/60000]  Loss: 0.000000\n",
      "Train Epoch: 83 [44800/60000]  Loss: 0.000000\n",
      "Train Epoch: 83 [51200/60000]  Loss: 0.000000\n",
      "Train Epoch: 83 [57600/60000]  Loss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 9922/10000 (99%)\n",
      "\n",
      "Train Epoch: 84 [0/60000]  Loss: 0.000000\n",
      "Train Epoch: 84 [6400/60000]  Loss: 0.000000\n",
      "Train Epoch: 84 [12800/60000]  Loss: 0.000000\n",
      "Train Epoch: 84 [19200/60000]  Loss: 0.000000\n",
      "Train Epoch: 84 [25600/60000]  Loss: 0.000000\n",
      "Train Epoch: 84 [32000/60000]  Loss: 0.000000\n",
      "Train Epoch: 84 [38400/60000]  Loss: 0.000016\n",
      "Train Epoch: 84 [44800/60000]  Loss: 0.000000\n",
      "Train Epoch: 84 [51200/60000]  Loss: 0.132239\n",
      "Train Epoch: 84 [57600/60000]  Loss: 0.091975\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 9890/10000 (99%)\n",
      "\n",
      "Train Epoch: 85 [0/60000]  Loss: 0.000000\n",
      "Train Epoch: 85 [6400/60000]  Loss: 0.000056\n",
      "Train Epoch: 85 [12800/60000]  Loss: 0.000000\n",
      "Train Epoch: 85 [19200/60000]  Loss: 0.000398\n",
      "Train Epoch: 85 [25600/60000]  Loss: 0.000013\n",
      "Train Epoch: 85 [32000/60000]  Loss: 0.000000\n",
      "Train Epoch: 85 [38400/60000]  Loss: 0.000000\n",
      "Train Epoch: 85 [44800/60000]  Loss: 0.000000\n",
      "Train Epoch: 85 [51200/60000]  Loss: 0.209234\n",
      "Train Epoch: 85 [57600/60000]  Loss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 9920/10000 (99%)\n",
      "\n",
      "Train Epoch: 86 [0/60000]  Loss: 0.000000\n",
      "Train Epoch: 86 [6400/60000]  Loss: 0.000000\n",
      "Train Epoch: 86 [12800/60000]  Loss: 0.000000\n",
      "Train Epoch: 86 [19200/60000]  Loss: 0.000000\n",
      "Train Epoch: 86 [25600/60000]  Loss: 0.000000\n",
      "Train Epoch: 86 [32000/60000]  Loss: 0.000000\n",
      "Train Epoch: 86 [38400/60000]  Loss: 0.000000\n",
      "Train Epoch: 86 [44800/60000]  Loss: 0.112387\n",
      "Train Epoch: 86 [51200/60000]  Loss: 0.000000\n",
      "Train Epoch: 86 [57600/60000]  Loss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 9918/10000 (99%)\n",
      "\n",
      "Train Epoch: 87 [0/60000]  Loss: 0.000000\n",
      "Train Epoch: 87 [6400/60000]  Loss: 0.000004\n",
      "Train Epoch: 87 [12800/60000]  Loss: 0.000000\n",
      "Train Epoch: 87 [19200/60000]  Loss: 0.000000\n",
      "Train Epoch: 87 [25600/60000]  Loss: 0.000000\n",
      "Train Epoch: 87 [32000/60000]  Loss: 0.000000\n",
      "Train Epoch: 87 [38400/60000]  Loss: 0.000000\n",
      "Train Epoch: 87 [44800/60000]  Loss: 0.000000\n",
      "Train Epoch: 87 [51200/60000]  Loss: 0.000000\n",
      "Train Epoch: 87 [57600/60000]  Loss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 9932/10000 (99%)\n",
      "\n",
      "Train Epoch: 88 [0/60000]  Loss: 0.000000\n",
      "Train Epoch: 88 [6400/60000]  Loss: 0.000001\n",
      "Train Epoch: 88 [12800/60000]  Loss: 0.000000\n",
      "Train Epoch: 88 [19200/60000]  Loss: 0.000000\n",
      "Train Epoch: 88 [25600/60000]  Loss: 0.002619\n",
      "Train Epoch: 88 [32000/60000]  Loss: 0.000000\n",
      "Train Epoch: 88 [38400/60000]  Loss: 0.000000\n",
      "Train Epoch: 88 [44800/60000]  Loss: 0.000000\n",
      "Train Epoch: 88 [51200/60000]  Loss: 0.000000\n",
      "Train Epoch: 88 [57600/60000]  Loss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 9909/10000 (99%)\n",
      "\n",
      "Train Epoch: 89 [0/60000]  Loss: 0.000000\n",
      "Train Epoch: 89 [6400/60000]  Loss: 0.000000\n",
      "Train Epoch: 89 [12800/60000]  Loss: 0.000000\n",
      "Train Epoch: 89 [19200/60000]  Loss: 0.000000\n",
      "Train Epoch: 89 [25600/60000]  Loss: 0.000000\n",
      "Train Epoch: 89 [32000/60000]  Loss: 0.000000\n",
      "Train Epoch: 89 [38400/60000]  Loss: 0.000000\n",
      "Train Epoch: 89 [44800/60000]  Loss: 0.029719\n",
      "Train Epoch: 89 [51200/60000]  Loss: 0.000000\n",
      "Train Epoch: 89 [57600/60000]  Loss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 9926/10000 (99%)\n",
      "\n",
      "Train Epoch: 90 [0/60000]  Loss: 0.000000\n",
      "Train Epoch: 90 [6400/60000]  Loss: 0.000002\n",
      "Train Epoch: 90 [12800/60000]  Loss: 0.000000\n",
      "Train Epoch: 90 [19200/60000]  Loss: 0.000000\n",
      "Train Epoch: 90 [25600/60000]  Loss: 0.000259\n",
      "Train Epoch: 90 [32000/60000]  Loss: 0.000000\n",
      "Train Epoch: 90 [38400/60000]  Loss: 0.000000\n",
      "Train Epoch: 90 [44800/60000]  Loss: 0.000000\n",
      "Train Epoch: 90 [51200/60000]  Loss: 0.000000\n",
      "Train Epoch: 90 [57600/60000]  Loss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 9910/10000 (99%)\n",
      "\n",
      "Train Epoch: 91 [0/60000]  Loss: 0.000215\n",
      "Train Epoch: 91 [6400/60000]  Loss: 0.000000\n",
      "Train Epoch: 91 [12800/60000]  Loss: 0.000000\n",
      "Train Epoch: 91 [19200/60000]  Loss: 0.000000\n",
      "Train Epoch: 91 [25600/60000]  Loss: 0.000000\n",
      "Train Epoch: 91 [32000/60000]  Loss: 0.000000\n",
      "Train Epoch: 91 [38400/60000]  Loss: 0.000000\n",
      "Train Epoch: 91 [44800/60000]  Loss: 0.019545\n",
      "Train Epoch: 91 [51200/60000]  Loss: 0.000000\n",
      "Train Epoch: 91 [57600/60000]  Loss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 9919/10000 (99%)\n",
      "\n",
      "Train Epoch: 92 [0/60000]  Loss: 0.000000\n",
      "Train Epoch: 92 [6400/60000]  Loss: 0.000000\n",
      "Train Epoch: 92 [12800/60000]  Loss: 0.000000\n",
      "Train Epoch: 92 [19200/60000]  Loss: 0.000000\n",
      "Train Epoch: 92 [25600/60000]  Loss: 0.000067\n",
      "Train Epoch: 92 [32000/60000]  Loss: 0.000000\n",
      "Train Epoch: 92 [38400/60000]  Loss: 0.000000\n",
      "Train Epoch: 92 [44800/60000]  Loss: 0.000000\n",
      "Train Epoch: 92 [51200/60000]  Loss: 0.000000\n",
      "Train Epoch: 92 [57600/60000]  Loss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 9919/10000 (99%)\n",
      "\n",
      "Train Epoch: 93 [0/60000]  Loss: 0.000000\n",
      "Train Epoch: 93 [6400/60000]  Loss: 0.000000\n",
      "Train Epoch: 93 [12800/60000]  Loss: 0.000000\n",
      "Train Epoch: 93 [19200/60000]  Loss: 0.000000\n",
      "Train Epoch: 93 [25600/60000]  Loss: 0.000000\n",
      "Train Epoch: 93 [32000/60000]  Loss: 0.000001\n",
      "Train Epoch: 93 [38400/60000]  Loss: 0.000000\n",
      "Train Epoch: 93 [44800/60000]  Loss: 0.000000\n",
      "Train Epoch: 93 [51200/60000]  Loss: 0.028856\n",
      "Train Epoch: 93 [57600/60000]  Loss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 9911/10000 (99%)\n",
      "\n",
      "Train Epoch: 94 [0/60000]  Loss: 0.012561\n",
      "Train Epoch: 94 [6400/60000]  Loss: 0.000000\n",
      "Train Epoch: 94 [12800/60000]  Loss: 0.000000\n",
      "Train Epoch: 94 [19200/60000]  Loss: 0.000000\n",
      "Train Epoch: 94 [25600/60000]  Loss: 0.000003\n",
      "Train Epoch: 94 [32000/60000]  Loss: 0.000000\n",
      "Train Epoch: 94 [38400/60000]  Loss: 0.000000\n",
      "Train Epoch: 94 [44800/60000]  Loss: 0.000000\n",
      "Train Epoch: 94 [51200/60000]  Loss: 0.000000\n",
      "Train Epoch: 94 [57600/60000]  Loss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 9900/10000 (99%)\n",
      "\n",
      "Train Epoch: 95 [0/60000]  Loss: 0.000000\n",
      "Train Epoch: 95 [6400/60000]  Loss: 0.000000\n",
      "Train Epoch: 95 [12800/60000]  Loss: 0.000000\n",
      "Train Epoch: 95 [19200/60000]  Loss: 0.000000\n",
      "Train Epoch: 95 [25600/60000]  Loss: 0.000000\n",
      "Train Epoch: 95 [32000/60000]  Loss: 0.000000\n",
      "Train Epoch: 95 [38400/60000]  Loss: 0.000000\n",
      "Train Epoch: 95 [44800/60000]  Loss: 0.000000\n",
      "Train Epoch: 95 [51200/60000]  Loss: 0.018915\n",
      "Train Epoch: 95 [57600/60000]  Loss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 9921/10000 (99%)\n",
      "\n",
      "Train Epoch: 96 [0/60000]  Loss: 0.000000\n",
      "Train Epoch: 96 [6400/60000]  Loss: 0.000000\n",
      "Train Epoch: 96 [12800/60000]  Loss: 0.000000\n",
      "Train Epoch: 96 [19200/60000]  Loss: 0.000000\n",
      "Train Epoch: 96 [25600/60000]  Loss: 0.000000\n",
      "Train Epoch: 96 [32000/60000]  Loss: 0.000000\n",
      "Train Epoch: 96 [38400/60000]  Loss: 0.000000\n",
      "Train Epoch: 96 [44800/60000]  Loss: 0.000000\n",
      "Train Epoch: 96 [51200/60000]  Loss: 0.000000\n",
      "Train Epoch: 96 [57600/60000]  Loss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.0002, Accuracy: 9890/10000 (99%)\n",
      "\n",
      "Train Epoch: 97 [0/60000]  Loss: 0.000000\n",
      "Train Epoch: 97 [6400/60000]  Loss: 0.000000\n",
      "Train Epoch: 97 [12800/60000]  Loss: 0.000000\n",
      "Train Epoch: 97 [19200/60000]  Loss: 0.000000\n",
      "Train Epoch: 97 [25600/60000]  Loss: 0.000000\n",
      "Train Epoch: 97 [32000/60000]  Loss: 0.000000\n",
      "Train Epoch: 97 [38400/60000]  Loss: 0.000000\n",
      "Train Epoch: 97 [44800/60000]  Loss: 0.000000\n",
      "Train Epoch: 97 [51200/60000]  Loss: 0.000000\n",
      "Train Epoch: 97 [57600/60000]  Loss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 9916/10000 (99%)\n",
      "\n",
      "Train Epoch: 98 [0/60000]  Loss: 0.000000\n",
      "Train Epoch: 98 [6400/60000]  Loss: 0.000000\n",
      "Train Epoch: 98 [12800/60000]  Loss: 0.000000\n",
      "Train Epoch: 98 [19200/60000]  Loss: 0.000000\n",
      "Train Epoch: 98 [25600/60000]  Loss: 0.000000\n",
      "Train Epoch: 98 [32000/60000]  Loss: 0.000000\n",
      "Train Epoch: 98 [38400/60000]  Loss: 0.000000\n",
      "Train Epoch: 98 [44800/60000]  Loss: 0.000000\n",
      "Train Epoch: 98 [51200/60000]  Loss: 0.000000\n",
      "Train Epoch: 98 [57600/60000]  Loss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 9920/10000 (99%)\n",
      "\n",
      "Train Epoch: 99 [0/60000]  Loss: 0.000003\n",
      "Train Epoch: 99 [6400/60000]  Loss: 0.021286\n",
      "Train Epoch: 99 [12800/60000]  Loss: 0.000000\n",
      "Train Epoch: 99 [19200/60000]  Loss: 0.000000\n",
      "Train Epoch: 99 [25600/60000]  Loss: 0.000000\n",
      "Train Epoch: 99 [32000/60000]  Loss: 0.000759\n",
      "Train Epoch: 99 [38400/60000]  Loss: 0.000000\n",
      "Train Epoch: 99 [44800/60000]  Loss: 0.000000\n",
      "Train Epoch: 99 [51200/60000]  Loss: 0.000000\n",
      "Train Epoch: 99 [57600/60000]  Loss: 0.000015\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 9920/10000 (99%)\n",
      "\n",
      "Train Epoch: 100 [0/60000]  Loss: 0.000000\n",
      "Train Epoch: 100 [6400/60000]  Loss: 0.000000\n",
      "Train Epoch: 100 [12800/60000]  Loss: 0.000000\n",
      "Train Epoch: 100 [19200/60000]  Loss: 0.000000\n",
      "Train Epoch: 100 [25600/60000]  Loss: 0.000000\n",
      "Train Epoch: 100 [32000/60000]  Loss: 0.000000\n",
      "Train Epoch: 100 [38400/60000]  Loss: 0.000000\n",
      "Train Epoch: 100 [44800/60000]  Loss: 0.000074\n",
      "Train Epoch: 100 [51200/60000]  Loss: 0.000022\n",
      "Train Epoch: 100 [57600/60000]  Loss: 0.000012\n",
      "\n",
      "Test set: Average loss: 0.0002, Accuracy: 9909/10000 (99%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    train(model, device, train_loader, optimizer, epoch)\n",
    "    test(model, device, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Model CNN sederhana yang dilatih pada dataset MNIST mencapai akurasi 99% secara konsisten dalam 100 epoch. Ini menunjukkan bahwa model mampu mengklasifikasikan gambar-gambar angka tangan (0-9) dengan sangat baik.\n",
    "\n",
    "- Proses pelatihan berlangsung selama 62 menit 34 detik. Waktu pelatihan ini cukup efisien mengingat akurasi yang sangat tinggi dicapai oleh model.\n",
    "\n",
    "- Rata-rata loss pada set pengujian sangat kecil, mendekati 0.0001 di sebagian besar epoch, menunjukkan bahwa model sangat jarang melakukan kesalahan.\n",
    "- Akurasi pengujian mendekati 100% pada hampir semua epoch, yang mencerminkan model yang overfitting dengan baik pada dataset MNIST, mengingat kesederhanaan dataset ini.\n",
    "- Akurasi pengujian relatif stabil di sekitar 99% setelah beberapa epoch awal. Hal ini menunjukkan bahwa model tidak mengalami masalah signifikan seperti underfitting atau overfitting yang drastis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagian 8: Evaluasi Model dengan Confusion Matrix\n",
    "Setelah model selesai dilatih, kita akan menggunakan **confusion matrix** dan **classification report** untuk mengevaluasi kinerja model pada tiap kelas.\n",
    "\n",
    "Buat confusion matrix untuk melihat performa klasifikasi per kelas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_preds = []\n",
    "true_labels = []\n",
    "model.eval()  # Set model ke mode evaluasi\n",
    "with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output = model(data)\n",
    "        preds = output.argmax(dim=1)\n",
    "        all_preds.extend(preds.cpu().numpy())  # Simpan prediksi\n",
    "        true_labels.extend(target.cpu().numpy())  # Simpan label sebenarnya\n",
    "\n",
    "# Membuat matriks kebingungan\n",
    "cm = confusion_matrix(true_labels, all_preds)\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Prediksi benar: Model memprediksi angka dengan sangat baik, misalnya angka 0 diprediksi dengan benar sebanyak 977 kali, angka 1 sebanyak 1135 kali, dan seterusnya di sepanjang diagonal utama.\n",
    "\n",
    "- Kesalahan prediksi: Beberapa kesalahan terjadi, seperti angka 5 diprediksi sebagai 3 sebanyak 10 kali, dan angka 9 diprediksi sebagai 8 sebanyak 8 kali.\n",
    "\n",
    "- Performa keseluruhan: Sebagian besar prediksi berada pada diagonal, menunjukkan akurasi tinggi dengan kesalahan klasifikasi yang sangat minim."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagian 9: Laporan Klasifikasi\n",
    "Tampilkan laporan precision, recall, F1-score untuk tiap kelas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99       980\n",
      "           1       0.99      1.00      1.00      1135\n",
      "           2       0.99      0.99      0.99      1032\n",
      "           3       0.99      0.99      0.99      1010\n",
      "           4       1.00      0.99      0.99       982\n",
      "           5       0.99      0.98      0.99       892\n",
      "           6       1.00      0.99      0.99       958\n",
      "           7       0.99      0.99      0.99      1028\n",
      "           8       0.98      0.99      0.99       974\n",
      "           9       0.99      0.98      0.98      1009\n",
      "\n",
      "    accuracy                           0.99     10000\n",
      "   macro avg       0.99      0.99      0.99     10000\n",
      "weighted avg       0.99      0.99      0.99     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(true_labels, all_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kesimpulan\n",
    "\n",
    "### 1. Proses Training\n",
    "- Model dilatih selama 100 epoch menggunakan dataset MNIST.\n",
    "- Pada setiap epoch, loss model secara bertahap menurun dan akurasi meningkat, yang menandakan model mempelajari pola dari data dengan baik.\n",
    "- Setelah 100 epoch, model mencapai akurasi training yang sangat tinggi, mendekati 99%.\n",
    "\n",
    "### 2. Evaluasi Hasil Eksperimen\n",
    "- **Akurasi Testing**: Setelah proses training, model dievaluasi menggunakan data testing sebanyak 10.000 gambar, dan model berhasil mencapai akurasi keseluruhan sebesar **99%**.\n",
    "- **Confusion Matrix**: Sebagian besar prediksi berada di diagonal utama, yang menunjukkan bahwa model mampu mengklasifikasikan angka-angka dengan tepat. Hanya terdapat sedikit kesalahan klasifikasi, seperti angka \"5\" yang kadang diprediksi sebagai \"3\", dan angka \"9\" yang diprediksi sebagai \"8\".\n",
    "- **Classification Report**: Precision, recall, dan f1-score rata-rata untuk semua kelas mendekati 0.99, yang menunjukkan bahwa model memiliki kemampuan generalisasi yang sangat baik pada data testing.\n",
    "\n",
    "### 3. Kesimpulan Akhir\n",
    "- Dengan akurasi testing sebesar **99%**, model yang dilatih menggunakan PyTorch menunjukkan performa yang sangat baik dalam mengklasifikasikan gambar-gambar angka dari dataset MNIST.\n",
    "- **Kesalahan klasifikasi** yang terjadi sangat sedikit dan tidak signifikan, menunjukkan model mampu menangani sebagian besar variasi gambar dengan sangat baik.\n",
    "- Proses training memakan waktu **62 menit 34 detik**, dan hasil evaluasi ini menunjukkan bahwa model CNN sederhana sudah sangat efektif untuk dataset MNIST.\n",
    "\n",
    "Secara keseluruhan, eksperimen ini menunjukkan bahwa model Convolutional Neural Network (CNN) yang dibangun menggunakan PyTorch dapat mengklasifikasikan gambar-gambar angka dengan akurasi yang sangat tinggi, dan memberikan performa yang sangat memuaskan pada dataset MNIST.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
